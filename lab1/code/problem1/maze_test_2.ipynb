{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Maze\n",
    "\n",
    "#### a) MDP formulation\n",
    "\n",
    "We propose the following MDP formulation: \n",
    "\n",
    "##### State space $\\mathcal{S}$\n",
    "We model the state space as the set of all possible positions of the player and all possible positions of the Minotaur in the maze. Formally, the state space is\n",
    "\n",
    "$$\\mathcal{S} = \\big\\lbrace (i,j,x,y):\\textrm{such that the cell\n",
    "} (i,j) \\textrm{ is the position of the player and not an obstacle}, \\\\   (x,y) \\textrm { is the position of the Minotaur}\\big\\rbrace.$$\n",
    "\n",
    "##### Action space $\\mathcal{A}$\n",
    "We allow the player to chose to either move `left`, `right`, `down`, `up` or not move at all (`stay`). Note that sometimes the player cannot move in a certain direction because of an obstacle or a wall, yet we permit this to be action. We will see that this is not an issue as long as we define our transition probabilities and rewards appropriately.\n",
    "Formally, the action space is\n",
    "\n",
    "$$\\mathcal{A} = \\lbrace \\textrm{up}, \\textrm{ down}, \\textrm{ left}, \\textrm{ right}, \\textrm{ stay} \\rbrace.$$\n",
    "\n",
    "##### Transition probabilities $\\mathcal{P}$\n",
    "Note that there is no randomness involved upon taking an action by the player. As a consequence, the transition probabilities are deterministic. More precisely, \n",
    "Only the player's next state is decided by the action deterministically. The action of the Minotaur is random and the transition probability is related to the position where the Minotaur is. \n",
    "- If at state (or position) $s$, the position of the Minotaur is in the middle of the map, then $\\mathbb{P}(s' \\vert s, a) = \\frac{1}{4}$. \n",
    "- If at state (or position)  $s$ , the position of the Minotaur is in the borders of the map (not in the corners), then $\\mathbb{P}(s' \\vert s, a) = \\frac{1}{3}$.\n",
    "- If at state (or position)  $s$ , the position of the Minotaur is in the corners of the map, then $\\mathbb{P}(s' \\vert s, a) = \\frac{1}{2}$.\n",
    "\n",
    "\n",
    "##### Rewards $\\mathcal{R}$\n",
    "The objective of the player is to find the exit of the maze while avoiding the obstacles.    \n",
    "   - If at state $s$, taking action $a$, leads to a wall or an obstacle then $r(s,a) = -\\infty$\n",
    "   - If at state $s$, taking action $a$, leads to caught by the Minotaur then $r(s,a) = -\\infty$\n",
    "   - If at state $s$, taking action $a$, leads to some other position in the maze that is not the exit nor a wall nor an obstacle, then $r(s, a) = -1$. \n",
    "   - If at state $s$, taking action $a$, leads to the exit then $r(s ,a) = 0$. \n",
    "  \n",
    "#### b) Moving in alternating rounds\n",
    "The problem should be the same. Since it is a Markov process, the action decisions made by the player only depend on the status before the decisions are made. Under such context, although the player and the Minotaur don't move in the same round, we can still regard the two steps, the player moving first and the Minotaur moving later, as one step. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "850e9087d56e71d4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'maze_1'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmaze_1\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmz\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'maze_1'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import maze_1 as mz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T16:00:39.179897200Z",
     "start_time": "2023-11-27T16:00:38.779506900Z"
    }
   },
   "id": "769c7c24dbe8bf97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0],\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T16:00:39.182942Z",
     "start_time": "2023-11-27T16:00:39.180928900Z"
    }
   },
   "id": "de2a2106177e612b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mz.draw_maze(maze)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T16:00:39.182434400Z"
    }
   },
   "id": "7da24840f6338a79"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ddb80614b385b05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = mz.Maze(maze)\n",
    "env.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T16:00:39.184116900Z"
    }
   },
   "id": "b0443191d0065fe6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "c) Solve the problem: find a policy that maximizes the probability of leaving the maze alive (in the shortest time possible) for T = 20. Illustrate this policy.\n",
    "\n",
    " The policy is solved as below. And the policy is a function related to the states and the time t. Such a function mapping can be illustrated as printed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddb5faa48b2c543"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finite horizon\n",
    "horizon = 20\n",
    "# Solve the MDP problem with dynamic programming \n",
    "V, policy= mz.dynamic_programming(env,horizon);\n",
    "np.set_printoptions(threshold=np.inf);\n",
    "print(policy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T16:00:39.188116900Z"
    }
   },
   "id": "de64ecad5deba260"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "method = 'DynProg';\n",
    "start  = (0, 0, 6, 5);\n",
    "path, _= env.simulate(start, policy, method);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T16:00:39.188116900Z",
     "start_time": "2023-11-27T16:00:39.188116900Z"
    }
   },
   "id": "5f977986d7b71dbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplt\n",
    "\n",
    "N = 1000;\n",
    "T = 31;\n",
    "rate = [];\n",
    "for t in range(1, T):\n",
    "    success_cnt = 0;\n",
    "    horizon = t;\n",
    "    # Solve the MDP problem with dynamic programming \n",
    "    V, policy= mz.dynamic_programming(env,horizon);\n",
    "    for i in range(0, N):\n",
    "        method = 'DynProg';\n",
    "        start  = (0, 0, 6, 5);\n",
    "        path, flag= env.simulate(start, policy, method);\n",
    "        if flag:\n",
    "            success_cnt = success_cnt + 1;\n",
    "    success_rate = success_cnt/N;\n",
    "    rate.append(success_rate);\n",
    "\n",
    "pyplt.plot(rate);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T16:00:39.188116900Z"
    }
   },
   "id": "cc2721aa7a7df0bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
